"""
Document Processing API Service
Handles file uploads, job creation, and status tracking
"""

from fastapi import FastAPI, HTTPException, File, UploadFile, Path, Body, Request, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
import tempfile
import os
import json
import time
import uuid
import re
import asyncio
import aiohttp
from datetime import datetime, timezone
from enum import Enum
from typing import Optional, List, Dict, Any

# Google Cloud imports
from google.cloud import storage, pubsub_v1, firestore
from google.api_core import exceptions as gcp_exceptions

# Security imports
from security import InputSanitizer, SecurityViolationType, security_metrics
from auth import rate_limiter, AuthConfig, AuditLogger, get_client_id, get_request_info, hash_sensitive_data
from text_analysis_metrics import text_analysis_metrics
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

# Initialize security
security = HTTPBearer(auto_error=False)

async def authenticate_request(
    request: Request,
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)
) -> Dict[str, Any]:
    """
    Authenticate API request and apply rate limiting
    """
    request_info = get_request_info(request)
    client_id = get_client_id(request, credentials)
    
    # Check authentication if required
    if AuthConfig.REQUIRE_AUTH:
        if not credentials or not credentials.credentials:
            AuditLogger.log_authentication_event(
                "missing_credentials", None, False, request_info["ip"],
                {"reason": "No credentials provided"}
            )
            raise HTTPException(
                status_code=401,
                detail={
                    "error": "Authentication required",
                    "message": "API key must be provided in Authorization header",
                    "format": "Bearer <api_key>"
                }
            )
        
        if credentials.credentials not in AuthConfig.VALID_API_KEYS:
            AuditLogger.log_authentication_event(
                "invalid_key", client_id, False, request_info["ip"],
                {"reason": "Invalid API key"}
            )
            raise HTTPException(
                status_code=401,
                detail={
                    "error": "Invalid API key",
                    "message": "The provided API key is not valid"
                }
            )
        
        AuditLogger.log_authentication_event(
            "success", client_id, True, request_info["ip"],
            {"method": "api_key"}
        )
    
    # Apply rate limiting
    allowed, rate_info = rate_limiter.is_allowed(client_id)
    
    if not allowed:
        AuditLogger.log_rate_limit_violation(
            client_id, request_info["ip"], "api_request", rate_info
        )
        
        raise HTTPException(
            status_code=429,
            detail={
                "error": "Rate limit exceeded",
                "message": rate_info.get("error", "Too many requests"),
                "retry_after": rate_info.get("retry_after", 3600),
                "limit": rate_info.get("limit"),
                "window": rate_info.get("window")
            },
            headers={"Retry-After": str(int(rate_info.get("retry_after", 3600)))}
        )
    
    return {
        "client_id": client_id,
        "authenticated": AuthConfig.REQUIRE_AUTH,
        "rate_limit": rate_info,
        "request_info": request_info
    }

def log_text_analysis_audit(
    auth_info: Dict[str, Any],
    analysis_type: str,
    entity_type: str,
    name: str,
    job_id: str
):
    """
    Log text analysis request for audit purposes
    """
    if AuthConfig.AUDIT_SENSITIVE_OPERATIONS:
        AuditLogger.log_text_analysis_request(
            client_id=auth_info["client_id"],
            analysis_type=analysis_type,
            entity_type=entity_type,
            name_hash=hash_sensitive_data(name),
            job_id=job_id,
            request_ip=auth_info["request_info"]["ip"],
            user_agent=auth_info["request_info"]["user_agent"]
        )

# Document type enum (matching existing model config)
class DocumentType(str, Enum):
    SKU = "sku"
    NPWP = "npwp"  
    KTP = "ktp"
    NIB = "nib"
    BPKB = "bpkb"
    SHMSHM = "shmshm"

# Text analysis enums
class AnalysisType(str, Enum):
    PEP_ANALYSIS = "pep-analysis"
    NEGATIVE_NEWS = "negative-news"
    LAW_INVOLVEMENT = "law-involvement"
    CORPORATE_NEGATIVE_NEWS = "corporate-negative-news"
    CORPORATE_LAW_INVOLVEMENT = "corporate-law-involvement"

class EntityType(str, Enum):
    PERSON = "person"
    CORPORATE = "corporate"

# Job status enum
class JobStatus(str, Enum):
    SUBMITTED = "submitted"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

# Model mapping (same as existing)
MODEL_CONFIG = {
    "sku": "image-screening-sku-analysis-grb",
    "npwp": "image-screening-npwp-analysis-grb", 
    "ktp": "image-screening-ktp-analysis-gemma",
    "nib": "image-screening-nib-analysis-grb",
    "bpkb": "image-screening-bpkb-analysis-gemini",
    "shmshm": "image-screening-shmshm-elektronik"
}

# Text analysis model configuration
TEXT_MODEL_CONFIG = {
    "pep-analysis": {
        "model": "politically-exposed-person-v2",
        "entity_types": ["person"],
        "description": "Political Exposure Person Analysis v2"
    },
    "negative-news": {
        "model": "negative-news", 
        "entity_types": ["person"],
        "description": "Individual Negative News Analysis"
    },
    "law-involvement": {
        "model": "law-involvement",
        "entity_types": ["person"], 
        "description": "Individual Law Involvement Analysis"
    },
    "corporate-negative-news": {
        "model": "negative-news-corporate",
        "entity_types": ["corporate"],
        "description": "Corporate Negative News Analysis"
    },
    "corporate-law-involvement": {
        "model": "law-involvement-corporate",
        "entity_types": ["corporate"],
        "description": "Corporate Law Involvement Analysis"
    }
}

# Pydantic models for text analysis
class TextAnalysisRequest(BaseModel):
    name: str = Field(..., min_length=1, max_length=200, description="Name to analyze (person or corporate)")
    entity_type: EntityType = Field(..., description="Type of entity being analyzed")
    additional_context: Optional[str] = Field(None, max_length=500, description="Optional additional context")
    
    @validator('name')
    def validate_name(cls, v):
        """Enhanced name validation with comprehensive security checks"""
        try:
            sanitized_name = InputSanitizer.sanitize_name(v, "name")
            security_metrics.record_validation(True)
            return sanitized_name
        except ValueError as e:
            security_metrics.record_validation(False, SecurityViolationType.INVALID_CHARACTERS)
            raise e
    
    @validator('additional_context')
    def validate_context(cls, v):
        """Enhanced context validation with security checks"""
        try:
            sanitized_context = InputSanitizer.sanitize_context(v)
            security_metrics.record_validation(True)
            return sanitized_context
        except ValueError as e:
            security_metrics.record_validation(False, SecurityViolationType.INVALID_CHARACTERS)
            raise e

class TextAnalysisResponse(BaseModel):
    success: bool
    job_id: str
    status: str
    analysis_type: str
    entity_type: str
    name: str
    model_name: str
    submitted_at: str
    processing_time: float
    message: str

# Initialize FastAPI app
app = FastAPI(
    title="Document Processing & Text Analysis API",
    description="Async document analysis and text-based name analysis service with Pub/Sub integration. Supports single and multi-file uploads for document processing, and person/corporate name analysis for PEP, negative news, and law involvement screening.",
    version="4.0.0"
)

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables for GCP clients (initialized at startup)
storage_client = None
publisher = None
firestore_client = None
bucket = None

# Configuration constants - matching Google Cloud Run settings
class ServiceConfig:
    PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT", "bni-prod-dma-bnimove-ai")
    BUCKET_NAME = os.getenv("GCS_BUCKET_NAME", "sbp-wrapper-bucket")
    PUBSUB_TOPIC = os.getenv("PUBSUB_TOPIC", "document-processing-request")
    FIRESTORE_DATABASE = os.getenv("FIRESTORE_DATABASE", "document-processing-firestore")
    MAX_FILE_SIZE_MB = int(os.getenv("MAX_FILE_SIZE_MB", "100"))
    MAX_FILES_PER_UPLOAD = int(os.getenv("MAX_FILES_PER_UPLOAD", "10"))
    SUPPORTED_EXTENSIONS = ['.pdf', '.jpg', '.jpeg', '.png']
    MULTI_FILE_SUPPORTED_TYPES = ["shmshm", "bpkb"]  # Only these types support multiple files

# Environment variables (for backward compatibility)
PROJECT_ID = ServiceConfig.PROJECT_ID
BUCKET_NAME = ServiceConfig.BUCKET_NAME
PUBSUB_TOPIC = ServiceConfig.PUBSUB_TOPIC
FIRESTORE_DATABASE = ServiceConfig.FIRESTORE_DATABASE

def initialize_gcp_clients():
    """Initialize Google Cloud clients"""
    global storage_client, publisher, firestore_client, bucket
    
    try:
        # Initialize Storage client
        storage_client = storage.Client(project=PROJECT_ID)
        bucket = storage_client.bucket(BUCKET_NAME)
        
        # Initialize Pub/Sub publisher
        publisher = pubsub_v1.PublisherClient()
        
        # Initialize Firestore client
        firestore_client = firestore.Client(
            project=PROJECT_ID, 
            database=FIRESTORE_DATABASE
        )
        
        print(f"‚úÖ GCP clients initialized for project: {PROJECT_ID}")
        
    except Exception as e:
        print(f"‚ùå Failed to initialize GCP clients: {e}")
        raise

@app.on_event("startup")
async def startup_event():
    """Initialize GCP clients on startup"""
    initialize_gcp_clients()

def upload_file_to_gcs(file_content: bytes, filename: str, job_id: str, page_number: int = None) -> str:
    """Upload file to Google Cloud Storage"""
    try:
        # Create blob path with optional page number for multi-file uploads
        if page_number is not None:
            # For multi-file uploads, add page number to maintain order
            file_ext = os.path.splitext(filename)[1]
            base_name = os.path.splitext(filename)[0]
            blob_name = f"uploads/{job_id}/page_{page_number:03d}_{base_name}{file_ext}"
        else:
            # Single file upload
            blob_name = f"uploads/{job_id}/{filename}"
            
        blob = bucket.blob(blob_name)
        
        # Upload file
        blob.upload_from_string(file_content)
        
        print(f"‚úÖ File uploaded to GCS: gs://{BUCKET_NAME}/{blob_name}")
        return f"gs://{BUCKET_NAME}/{blob_name}"
        
    except Exception as e:
        print(f"‚ùå GCS upload failed: {e}")
        raise HTTPException(status_code=500, detail=f"File upload failed: {str(e)}")

def upload_multiple_files_to_gcs(files_data: List[tuple], job_id: str) -> List[str]:
    """Upload multiple files to GCS maintaining page order"""
    gcs_paths = []
    
    for page_num, (file_content, filename) in enumerate(files_data, 1):
        gcs_path = upload_file_to_gcs(file_content, filename, job_id, page_num)
        gcs_paths.append(gcs_path)
    
    return gcs_paths

def create_job_record(job_id: str, document_type: str, filename: str, gcs_path: str, 
                     is_multi_file: bool = False, file_count: int = 1, 
                     all_filenames: List[str] = None) -> dict:
    """Create job record in Firestore"""
    try:
        job_data = {
            "job_id": job_id,
            "status": JobStatus.SUBMITTED.value,
            "document_type": document_type,
            "filename": filename,
            "gcs_path": gcs_path,
            "model_name": MODEL_CONFIG.get(document_type),
            "created_at": datetime.now(timezone.utc),
            "updated_at": datetime.now(timezone.utc),
            "result": None,
            "error": None,
            "is_multi_file": is_multi_file,
            "file_count": file_count
        }
        
        # Add additional info for multi-file uploads
        if is_multi_file and all_filenames:
            job_data["all_filenames"] = all_filenames
            # For multi-file, gcs_path should be the list, and we also store it separately for clarity
            job_data["gcs_paths"] = gcs_path if isinstance(gcs_path, list) else [gcs_path]
            # Ensure gcs_path is the list for multi-file (worker expects this)
            if isinstance(gcs_path, list):
                job_data["gcs_path"] = gcs_path
        
        # Save to Firestore
        doc_ref = firestore_client.collection("jobs").document(job_id)
        doc_ref.set(job_data)
        
        print(f"‚úÖ Job record created: {job_id} ({'multi-file' if is_multi_file else 'single-file'})")
        return job_data
        
    except Exception as e:
        print(f"‚ùå Firestore create failed: {e}")
        raise HTTPException(status_code=500, detail=f"Job creation failed: {str(e)}")

def publish_processing_message(job_id: str, document_type: str, gcs_path: str, filename: str, 
                             is_multi_file: bool = False, file_count: int = 1):
    """Publish message to Pub/Sub for processing"""
    try:
        # Create message payload
        message_data = {
            "job_id": job_id,
            "document_type": document_type,
            "gcs_path": gcs_path,
            "filename": filename,
            "model_name": MODEL_CONFIG.get(document_type),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "is_multi_file": is_multi_file,
            "file_count": file_count
        }
        
        # Debug logging for multi-file
        if is_multi_file:
            print(f"üîç Publishing multi-file message:")
            print(f"   - Job ID: {job_id}")
            print(f"   - File count: {file_count}")
            print(f"   - GCS path type: {type(gcs_path)}")
            print(f"   - GCS paths: {gcs_path}")
        
        # Convert to JSON bytes
        message_json = json.dumps(message_data).encode('utf-8')
        
        # Publish message
        topic_path = publisher.topic_path(PROJECT_ID, PUBSUB_TOPIC)
        future = publisher.publish(topic_path, message_json)
        
        # Wait for publish to complete
        message_id = future.result()
        
        print(f"‚úÖ Message published to Pub/Sub: {message_id}")
        return message_id
        
    except Exception as e:
        print(f"‚ùå Pub/Sub publish failed: {e}")
        raise HTTPException(status_code=500, detail=f"Message publish failed: {str(e)}")

async def validate_text_analysis_request(analysis_type: AnalysisType, entity_type: EntityType, name: str) -> Optional[str]:
    """
    Validate text analysis request parameters and check model availability
    Returns fallback analysis type if primary model is unavailable, None if validation fails
    """
    
    # Check if analysis type is supported
    if analysis_type not in TEXT_MODEL_CONFIG:
        available_types = list(TEXT_MODEL_CONFIG.keys())
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported analysis type '{analysis_type}'. Available types: {available_types}"
        )
    
    # Check entity type compatibility with analysis type
    model_config = TEXT_MODEL_CONFIG[analysis_type]
    if entity_type not in model_config["entity_types"]:
        supported_entities = model_config["entity_types"]
        raise HTTPException(
            status_code=400,
            detail=f"Entity type '{entity_type}' is not supported for analysis type '{analysis_type}'. "
                   f"Supported entity types for {analysis_type}: {supported_entities}"
        )
    
    # Additional name validation
    if not name or len(name.strip()) == 0:
        raise HTTPException(
            status_code=400,
            detail="Name cannot be empty or contain only whitespace"
        )
    
    # Check model availability (Requirement 6.3)
    is_available = await validate_model_availability(analysis_type.value)
    
    if not is_available:
        # Try to find a fallback model (Requirement 6.5)
        fallback_type = get_fallback_model(analysis_type.value, entity_type.value)
        
        if fallback_type:
            # Check if fallback model is available
            fallback_available = await validate_model_availability(fallback_type)
            
            if fallback_available:
                print(f"‚ö†Ô∏è Primary model '{analysis_type}' unavailable, using fallback '{fallback_type}'")
                return fallback_type
            else:
                print(f"‚ùå Both primary model '{analysis_type}' and fallback '{fallback_type}' unavailable")
        
        # No fallback available or fallback also unavailable
        raise HTTPException(
            status_code=503,
            detail=f"Text analysis model for '{analysis_type}' is currently unavailable. "
                   f"Please try again later or contact support if the issue persists."
        )
    
    # Log validation success
    print(f"‚úÖ Text analysis validation passed: {analysis_type} for {entity_type} entity '{name[:50]}...'")
    return None  # No fallback needed, primary model is available

def create_text_analysis_job_record(job_id: str, analysis_type: str, entity_type: str, 
                                  name: str, additional_context: Optional[str] = None) -> dict:
    """Create text analysis job record in Firestore"""
    try:
        model_config = TEXT_MODEL_CONFIG[analysis_type]
        
        job_data = {
            "job_id": job_id,
            "job_type": "text_analysis",  # New field to distinguish from document jobs
            "status": JobStatus.SUBMITTED.value,
            "analysis_type": analysis_type,
            "entity_type": entity_type,
            "name": name,
            "additional_context": additional_context,
            "model_name": model_config["model"],
            "created_at": datetime.now(timezone.utc),
            "updated_at": datetime.now(timezone.utc),
            "result": None,
            "error": None,
            # Document processing fields (set to None for text analysis)
            "document_type": None,
            "filename": None,
            "gcs_path": None,
            "is_multi_file": False,
            "file_count": 0
        }
        
        # Save to Firestore
        doc_ref = firestore_client.collection("jobs").document(job_id)
        doc_ref.set(job_data)
        
        print(f"‚úÖ Text analysis job record created: {job_id} ({analysis_type} for {entity_type})")
        return job_data
        
    except Exception as e:
        print(f"‚ùå Firestore text analysis job creation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Text analysis job creation failed: {str(e)}")

def publish_text_analysis_message(job_id: str, analysis_type: str, entity_type: str, 
                                name: str, additional_context: Optional[str] = None):
    """Publish text analysis message to Pub/Sub for processing"""
    try:
        model_config = TEXT_MODEL_CONFIG[analysis_type]
        
        # Create message payload
        message_data = {
            "job_id": job_id,
            "job_type": "text_analysis",
            "analysis_type": analysis_type,
            "entity_type": entity_type,
            "name": name,
            "additional_context": additional_context,
            "model_name": model_config["model"],
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        print(f"üîç Publishing text analysis message:")
        print(f"   - Job ID: {job_id}")
        print(f"   - Analysis type: {analysis_type}")
        print(f"   - Entity type: {entity_type}")
        print(f"   - Model: {model_config['model']}")
        
        # Convert to JSON bytes
        message_json = json.dumps(message_data).encode('utf-8')
        
        # Publish message
        topic_path = publisher.topic_path(PROJECT_ID, PUBSUB_TOPIC)
        future = publisher.publish(topic_path, message_json)
        
        # Wait for publish to complete
        message_id = future.result()
        
        print(f"‚úÖ Text analysis message published to Pub/Sub: {message_id}")
        return message_id
        
    except Exception as e:
        print(f"‚ùå Text analysis Pub/Sub publish failed: {e}")
        raise HTTPException(status_code=500, detail=f"Text analysis message publish failed: {str(e)}")

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "service": "Document Processing API",
        "status": "running",
        "version": "4.0.0",  # Updated version for text analysis support
        "supported_formats": ["PDF", "JPG", "JPEG", "PNG"],
        "available_models": list(MODEL_CONFIG.keys()),
        "text_analysis_models": list(TEXT_MODEL_CONFIG.keys()),
        "features": {
            "single_file_upload": "All document types",
            "multi_file_upload": f"Only {', '.join(ServiceConfig.MULTI_FILE_SUPPORTED_TYPES)} document types",
            "text_analysis": "Person and corporate name analysis",
            "max_files_per_upload": ServiceConfig.MAX_FILES_PER_UPLOAD,
            "max_file_size_mb": ServiceConfig.MAX_FILE_SIZE_MB
        },
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "infrastructure": {
            "project_id": PROJECT_ID,
            "bucket": BUCKET_NAME,
            "pubsub_topic": PUBSUB_TOPIC,
            "firestore_db": FIRESTORE_DATABASE
        }
    }

@app.get("/health")
async def health():
    """Detailed health check including text analysis models and comprehensive metrics"""
    health_status = {"status": "healthy", "checks": {}}
    
    try:
        # Check GCS bucket access
        bucket.get_blob("health-check") or True
        health_status["checks"]["gcs"] = "‚úÖ accessible"
    except Exception as e:
        health_status["checks"]["gcs"] = f"‚ùå error: {str(e)[:100]}"
        health_status["status"] = "degraded"
    
    try:
        # Check Firestore access
        firestore_client.collection("jobs").limit(1).get()
        health_status["checks"]["firestore"] = "‚úÖ accessible"
    except Exception as e:
        health_status["checks"]["firestore"] = f"‚ùå error: {str(e)[:100]}"
        health_status["status"] = "degraded"
    
    try:
        # Check Pub/Sub topic access
        topic_path = publisher.topic_path(PROJECT_ID, PUBSUB_TOPIC)
        publisher.get_topic(request={"topic": topic_path})
        health_status["checks"]["pubsub"] = "‚úÖ accessible"
    except Exception as e:
        health_status["checks"]["pubsub"] = f"‚ùå error: {str(e)[:100]}"
        health_status["status"] = "degraded"
    
    try:
        # Check text analysis models health
        text_models_health = await check_text_models_health()
        if text_models_health["overall_status"] == "healthy":
            health_status["checks"]["text_models"] = f"‚úÖ {text_models_health['healthy_models']}/{text_models_health['total_models']} models healthy"
        elif text_models_health["overall_status"] == "degraded":
            health_status["checks"]["text_models"] = f"‚ö†Ô∏è {text_models_health['healthy_models']}/{text_models_health['total_models']} models healthy"
            if health_status["status"] == "healthy":
                health_status["status"] = "degraded"
        else:
            health_status["checks"]["text_models"] = f"‚ùå {text_models_health['healthy_models']}/{text_models_health['total_models']} models healthy"
            health_status["status"] = "degraded"
            
        # Add detailed text analysis model information
        health_status["text_analysis_details"] = text_models_health
        
    except Exception as e:
        health_status["checks"]["text_models"] = f"‚ùå error: {str(e)[:100]}"
        health_status["status"] = "degraded"
    
    try:
        # Add text analysis metrics summary to health check
        text_metrics = text_analysis_metrics.get_comprehensive_metrics()
        health_status["text_analysis_metrics_summary"] = {
            "total_requests": text_metrics["overview"]["total_requests"],
            "success_rate": text_metrics["overview"]["success_rate"],
            "avg_latency_ms": text_metrics["overview"]["avg_latency_ms"],
            "requests_per_minute": text_metrics["overview"]["requests_per_minute"],
            "last_request": text_metrics["overview"]["last_request"],
            "uptime_seconds": text_metrics["overview"]["uptime_seconds"]
        }
        
        # Check if text analysis metrics indicate any issues
        if text_metrics["overview"]["success_rate"] < 90 and text_metrics["overview"]["total_requests"] > 10:
            health_status["checks"]["text_analysis_performance"] = f"‚ö†Ô∏è success rate {text_metrics['overview']['success_rate']}% below threshold"
            if health_status["status"] == "healthy":
                health_status["status"] = "degraded"
        else:
            health_status["checks"]["text_analysis_performance"] = "‚úÖ performance within acceptable range"
            
    except Exception as e:
        health_status["checks"]["text_analysis_metrics"] = f"‚ùå metrics error: {str(e)[:100]}"
    
    # Add service capabilities to health check
    health_status["service_capabilities"] = {
        "document_processing": "‚úÖ enabled",
        "text_analysis": "‚úÖ enabled", 
        "multi_file_support": "‚úÖ enabled",
        "authentication": "‚úÖ enabled" if AuthConfig.REQUIRE_AUTH else "‚ö†Ô∏è disabled",
        "rate_limiting": "‚úÖ enabled",
        "security_validation": "‚úÖ enabled",
        "metrics_tracking": "‚úÖ enabled",
        "audit_logging": "‚úÖ enabled" if AuthConfig.AUDIT_SENSITIVE_OPERATIONS else "‚ö†Ô∏è disabled"
    }
    
    # Add alerting thresholds information
    health_status["alerting_thresholds"] = {
        "text_analysis_success_rate_min": 90,
        "text_analysis_avg_latency_max_ms": 5000,
        "model_availability_min": 80,
        "requests_per_minute_max": 100
    }
    
    return health_status

async def check_text_model_availability(model_name: str, timeout: int = 5) -> Dict[str, Any]:
    """Check if a text analysis model is available and responsive"""
    start_time = time.time()
    
    try:
        # For now, we'll simulate model health checks since we don't have actual model endpoints
        # In a real implementation, this would make HTTP requests to model endpoints
        
        # Simulate network delay
        await asyncio.sleep(0.1)
        
        # Mock health check logic - in production, this would be actual HTTP calls
        # For demonstration, we'll consider all models healthy except for specific test cases
        if "unavailable" in model_name.lower():
            response_time = time.time() - start_time
            
            # Record availability check in metrics
            text_analysis_metrics.record_model_availability_check(model_name, False, response_time)
            
            return {
                "status": "unhealthy",
                "response_time_ms": None,
                "error": "Model endpoint not responding",
                "last_checked": datetime.now(timezone.utc).isoformat()
            }
        
        response_time = time.time() - start_time
        mock_model_response_time = 0.15  # Mock response time in seconds
        
        # Record availability check in metrics
        text_analysis_metrics.record_model_availability_check(model_name, True, response_time)
        
        return {
            "status": "healthy",
            "response_time_ms": int(mock_model_response_time * 1000),
            "error": None,
            "last_checked": datetime.now(timezone.utc).isoformat()
        }
        
    except asyncio.TimeoutError:
        response_time = time.time() - start_time
        
        # Record timeout in metrics
        text_analysis_metrics.record_model_availability_check(model_name, False, response_time)
        
        return {
            "status": "timeout",
            "response_time_ms": None,
            "error": f"Model health check timed out after {timeout}s",
            "last_checked": datetime.now(timezone.utc).isoformat()
        }
    except Exception as e:
        response_time = time.time() - start_time
        
        # Record error in metrics
        text_analysis_metrics.record_model_availability_check(model_name, False, response_time)
        
        return {
            "status": "error",
            "response_time_ms": None,
            "error": f"Health check failed: {str(e)}",
            "last_checked": datetime.now(timezone.utc).isoformat()
        }

async def validate_model_availability(analysis_type: str) -> bool:
    """Validate that the model for a given analysis type is available"""
    if analysis_type not in TEXT_MODEL_CONFIG:
        return False
    
    model_config = TEXT_MODEL_CONFIG[analysis_type]
    model_name = model_config["model"]
    
    health_result = await check_text_model_availability(model_name)
    return health_result["status"] == "healthy"

def get_fallback_model(analysis_type: str, entity_type: str) -> Optional[str]:
    """Get a fallback model when the primary model is unavailable"""
    # Define fallback strategies for each analysis type
    fallback_mapping = {
        "pep-analysis": None,  # No fallback for PEP analysis (specialized model)
        "negative-news": "negative-news-corporate" if entity_type == "corporate" else None,
        "law-involvement": "law-involvement-corporate" if entity_type == "corporate" else None,
        "corporate-negative-news": "negative-news" if entity_type == "person" else None,
        "corporate-law-involvement": "law-involvement" if entity_type == "person" else None
    }
    
    fallback_analysis_type = fallback_mapping.get(analysis_type)
    if fallback_analysis_type and fallback_analysis_type in TEXT_MODEL_CONFIG:
        return fallback_analysis_type
    
    return None

@app.get("/api/text-models/health")
async def check_text_models_health():
    """Check health status of all text analysis models"""
    health_results = {}
    overall_status = "healthy"
    healthy_count = 0
    total_count = len(TEXT_MODEL_CONFIG)
    
    # Check each model's health
    for analysis_type, config in TEXT_MODEL_CONFIG.items():
        model_name = config["model"]
        health_result = await check_text_model_availability(model_name)
        
        health_results[analysis_type] = {
            "model_name": model_name,
            "description": config["description"],
            "supported_entity_types": config["entity_types"],
            "health": health_result
        }
        
        if health_result["status"] == "healthy":
            healthy_count += 1
        elif overall_status == "healthy":
            overall_status = "degraded"
    
    # Determine overall status
    if healthy_count == 0:
        overall_status = "unhealthy"
    elif healthy_count < total_count:
        overall_status = "degraded"
    
    return {
        "overall_status": overall_status,
        "healthy_models": healthy_count,
        "total_models": total_count,
        "models": health_results,
        "fallback_available": {
            analysis_type: get_fallback_model(analysis_type, "person") is not None or 
                          get_fallback_model(analysis_type, "corporate") is not None
            for analysis_type in TEXT_MODEL_CONFIG.keys()
        },
        "checked_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/models")
async def get_available_models():
    """Get list of available models and document types"""
    return {
        "models": MODEL_CONFIG,
        "supported_formats": ["PDF", "JPG", "JPEG", "PNG"],
        "multi_file_support": {
            "supported_types": ServiceConfig.MULTI_FILE_SUPPORTED_TYPES,
            "max_files_per_upload": ServiceConfig.MAX_FILES_PER_UPLOAD,
            "description": "Multiple file upload is supported only for SHMSHM and BPKB document types"
        },
        "document_types": [
            {"type": "sku", "name": "Surat Keterangan Usaha", "model": MODEL_CONFIG["sku"], "supports_multi_file": False},
            {"type": "npwp", "name": "NPWP", "model": MODEL_CONFIG["npwp"], "supports_multi_file": False},
            {"type": "ktp", "name": "KTP", "model": MODEL_CONFIG["ktp"], "supports_multi_file": False},
            {"type": "nib", "name": "NIB", "model": MODEL_CONFIG["nib"], "supports_multi_file": False},
            {"type": "bpkb", "name": "BPKB", "model": MODEL_CONFIG["bpkb"], "supports_multi_file": True},
            {"type": "shmshm", "name": "SHM/SHGB", "model": MODEL_CONFIG["shmshm"], "supports_multi_file": True}
        ]
    }

@app.get("/api/text-models")
async def get_text_analysis_models(auth_info: Dict[str, Any] = Depends(authenticate_request)):
    """
    Get list of available text analysis models and configurations
    Enhanced with authentication and rate limiting
    """
    
    # Build entity type compatibility matrix
    entity_compatibility = {}
    for analysis_type, config in TEXT_MODEL_CONFIG.items():
        for entity_type in config["entity_types"]:
            if entity_type not in entity_compatibility:
                entity_compatibility[entity_type] = []
            entity_compatibility[entity_type].append(analysis_type)
    
    # Build detailed model information
    models_detail = []
    for analysis_type, config in TEXT_MODEL_CONFIG.items():
        models_detail.append({
            "analysis_type": analysis_type,
            "model_name": config["model"],
            "description": config["description"],
            "supported_entity_types": config["entity_types"],
            "endpoint": f"/api/analyze-text/{analysis_type}"
        })
    
    return {
        "text_analysis_models": TEXT_MODEL_CONFIG,
        "models_detail": models_detail,
        "entity_compatibility_matrix": entity_compatibility,
        "supported_entity_types": list(EntityType),
        "supported_analysis_types": list(AnalysisType),
        "usage": {
            "endpoint_pattern": "/api/analyze-text/{analysis_type}",
            "method": "POST",
            "required_fields": ["name", "entity_type"],
            "optional_fields": ["additional_context"],
            "example_request": {
                "name": "John Doe",
                "entity_type": "person",
                "additional_context": "CEO of Example Corp"
            }
        },
        "compatibility_rules": [
            "PEP analysis only supports person entity type",
            "Negative news analysis supports both person and corporate entity types",
            "Law involvement analysis supports both person and corporate entity types",
            "Corporate-specific models only support corporate entity type"
        ]
    }

@app.post("/api/analyze/{document_type}")
async def submit_analysis(
    document_type: DocumentType,
    files: List[UploadFile] = File(...)
):
    """
    Submit document(s) for async analysis
    Supports single file for all document types
    Supports multiple files only for SHMSHM and BPKB document types
    Returns job_id for status tracking
    """
    start_time = time.time()
    
    # Validate document type
    if document_type not in MODEL_CONFIG:
        raise HTTPException(
            status_code=400, 
            detail=f"Unsupported document type. Available: {list(MODEL_CONFIG.keys())}"
        )
    
    # Check if multiple files are provided
    is_multi_file = len(files) > 1
    
    # Validate multiple file upload restrictions
    if is_multi_file and document_type.value not in ServiceConfig.MULTI_FILE_SUPPORTED_TYPES:
        raise HTTPException(
            status_code=400,
            detail=f"Multiple file upload is only supported for {', '.join(ServiceConfig.MULTI_FILE_SUPPORTED_TYPES)} document types. "
                   f"Document type '{document_type}' only supports single file upload."
        )
    
    # Validate file count
    if len(files) > ServiceConfig.MAX_FILES_PER_UPLOAD:
        raise HTTPException(
            status_code=400,
            detail=f"Too many files. Maximum {ServiceConfig.MAX_FILES_PER_UPLOAD} files allowed per upload."
        )
    
    if len(files) == 0:
        raise HTTPException(status_code=400, detail="No files provided")
    
    print(f"üì§ Received request: {document_type} - {len(files)} file(s)")
    
    # Validate each file
    total_size = 0
    file_contents = []
    filenames = []
    
    for i, file in enumerate(files):
        # Validate file type
        if not any(file.filename.lower().endswith(ext) for ext in ServiceConfig.SUPPORTED_EXTENSIONS):
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported file type for '{file.filename}'. Supported: {', '.join(ServiceConfig.SUPPORTED_EXTENSIONS)}"
            )
        
        # Read file content
        file_content = await file.read()
        file_size_mb = len(file_content) / (1024 * 1024)
        
        # Individual file size validation
        file_size_limit = ServiceConfig.MAX_FILE_SIZE_MB * 1024 * 1024
        if len(file_content) > file_size_limit:
            raise HTTPException(
                status_code=400, 
                detail=f"File '{file.filename}' too large ({file_size_mb:.2f}MB). Max {ServiceConfig.MAX_FILE_SIZE_MB}MB per file."
            )
        
        total_size += len(file_content)
        file_contents.append(file_content)
        filenames.append(file.filename)
        
        print(f"üìÅ File {i+1}: {file.filename} ({file_size_mb:.2f}MB)")
    
    # Total size validation for multi-file uploads
    total_size_mb = total_size / (1024 * 1024)
    max_total_size = ServiceConfig.MAX_FILE_SIZE_MB * len(files)
    if total_size > max_total_size * 1024 * 1024:
        raise HTTPException(
            status_code=400,
            detail=f"Total upload size too large ({total_size_mb:.2f}MB). Max {max_total_size}MB total."
        )
    
    try:
        # Generate job ID
        job_id = str(uuid.uuid4())
        
        if is_multi_file:
            # Handle multiple file upload
            files_data = list(zip(file_contents, filenames))
            gcs_paths = upload_multiple_files_to_gcs(files_data, job_id)
            
            # Use first filename as primary, but store all filenames
            primary_filename = filenames[0]
            combined_filename = f"multi_file_document_{len(files)}_pages"
            
            print(f"üîç Multi-file upload processing:")
            print(f"   - Job ID: {job_id}")
            print(f"   - File count: {len(files)}")
            print(f"   - GCS paths: {gcs_paths}")
            print(f"   - Combined filename: {combined_filename}")
            
            # Create job record with multi-file info
            job_data = create_job_record(
                job_id, document_type, combined_filename, gcs_paths,
                is_multi_file=True, file_count=len(files), all_filenames=filenames
            )
            
            # Publish message with multi-file info
            message_id = publish_processing_message(
                job_id, document_type, gcs_paths, combined_filename,
                is_multi_file=True, file_count=len(files)
            )
            
            print(f"‚úÖ Multi-file job submitted: {job_id} ({len(files)} files, {total_size_mb:.2f}MB total)")
            
            return {
                "success": True,
                "job_id": job_id,
                "status": JobStatus.SUBMITTED.value,
                "document_type": document_type,
                "filename": combined_filename,
                "file_count": len(files),
                "all_filenames": filenames,
                "is_multi_file": True,
                "total_size_mb": round(total_size_mb, 2),
                "model_name": MODEL_CONFIG[document_type],
                "message_id": message_id,
                "submitted_at": datetime.now(timezone.utc).isoformat(),
                "processing_time": round(time.time() - start_time, 2),
                "message": f"Multi-file job submitted successfully ({len(files)} files). Use GET /api/status/{job_id} to check progress."
            }
        else:
            # Handle single file upload (existing logic)
            file_content = file_contents[0]
            filename = filenames[0]
            
            # Upload to GCS
            gcs_path = upload_file_to_gcs(file_content, filename, job_id)
            
            # Create job record in Firestore
            job_data = create_job_record(job_id, document_type, filename, gcs_path)
            
            # Publish to Pub/Sub for processing
            message_id = publish_processing_message(job_id, document_type, gcs_path, filename)
            
            processing_time = time.time() - start_time
            
            print(f"‚úÖ Single-file job submitted: {job_id} in {processing_time:.2f}s")
            
            return {
                "success": True,
                "job_id": job_id,
                "status": JobStatus.SUBMITTED.value,
                "document_type": document_type,
                "filename": filename,
                "file_count": 1,
                "is_multi_file": False,
                "model_name": MODEL_CONFIG[document_type],
                "message_id": message_id,
                "submitted_at": datetime.now(timezone.utc).isoformat(),
                "processing_time": round(processing_time, 2),
                "message": f"Job submitted successfully. Use GET /api/status/{job_id} to check progress."
            }
        
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"Job submission failed: {str(e)}"
        print(f"‚ùå {error_msg}")
        
        raise HTTPException(
            status_code=500,
            detail={
                "error": error_msg,
                "job_id": job_id if 'job_id' in locals() else None,
                "processing_time": round(processing_time, 2)
            }
        )

@app.get("/api/status/{job_id}")
async def get_job_status(job_id: str):
    """Get job status and result"""
    try:
        # Get job from Firestore
        doc_ref = firestore_client.collection("jobs").document(job_id)
        doc = doc_ref.get()
        
        if not doc.exists:
            raise HTTPException(status_code=404, detail=f"Job {job_id} not found")
        
        job_data = doc.to_dict()
        
        # Convert timestamps to ISO format if they exist
        if job_data.get("created_at"):
            job_data["created_at"] = job_data["created_at"].isoformat()
        if job_data.get("updated_at"):
            job_data["updated_at"] = job_data["updated_at"].isoformat()
        if job_data.get("completed_at"):
            job_data["completed_at"] = job_data["completed_at"].isoformat()
        
        print(f"üìä Status check: {job_id} - {job_data.get('status')}")
        
        return job_data
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Status check failed: {e}")
        raise HTTPException(status_code=500, detail=f"Status check failed: {str(e)}")

@app.get("/api/jobs")
async def list_jobs(
    limit: int = 20, 
    status: Optional[JobStatus] = None,
    document_type: Optional[DocumentType] = None
):
    """List recent jobs with optional filtering"""
    try:
        # Build query
        query = firestore_client.collection("jobs")
        
        if status:
            query = query.where("status", "==", status.value)
        
        if document_type:
            query = query.where("document_type", "==", document_type.value)
        
        # Order by creation time and limit
        query = query.order_by("created_at", direction=firestore.Query.DESCENDING)
        query = query.limit(limit)
        
        # Execute query
        docs = query.get()
        
        jobs = []
        for doc in docs:
            job_data = doc.to_dict()
            
            # Convert timestamps to ISO format
            if job_data.get("created_at"):
                job_data["created_at"] = job_data["created_at"].isoformat()
            if job_data.get("updated_at"):
                job_data["updated_at"] = job_data["updated_at"].isoformat()
            if job_data.get("completed_at"):
                job_data["completed_at"] = job_data["completed_at"].isoformat()
            
            jobs.append(job_data)
        
        return {
            "jobs": jobs,
            "count": len(jobs),
            "filters": {
                "status": status,
                "document_type": document_type,
                "limit": limit
            }
        }
        
    except Exception as e:
        print(f"‚ùå Jobs list failed: {e}")
        raise HTTPException(status_code=500, detail=f"Jobs listing failed: {str(e)}")

@app.get("/api/security/metrics")
async def get_security_metrics():
    """Get security validation metrics for monitoring"""
    return {
        "security_metrics": security_metrics.get_metrics(),
        "rate_limiting": rate_limiter.get_stats(),
        "authentication": {
            "required": AuthConfig.REQUIRE_AUTH,
            "audit_enabled": AuthConfig.AUDIT_SENSITIVE_OPERATIONS,
            "rate_limits": {
                "requests_per_hour": AuthConfig.RATE_LIMIT_REQUESTS,
                "burst_per_minute": AuthConfig.RATE_LIMIT_BURST
            }
        },
        "validation_rules": {
            "name_length_range": f"{InputSanitizer.MIN_NAME_LENGTH}-{InputSanitizer.MAX_NAME_LENGTH}",
            "context_max_length": InputSanitizer.MAX_CONTEXT_LENGTH,
            "allowed_characters": "Letters, numbers, spaces, and basic punctuation (.-,'&())",
            "security_features": [
                "HTML escaping",
                "Unicode normalization", 
                "Injection pattern detection",
                "Control character filtering",
                "Comprehensive logging"
            ]
        },
        "checked_at": datetime.now(timezone.utc).isoformat()
    }

@app.get("/api/text-analysis/metrics")
async def get_text_analysis_metrics(auth_info: Dict[str, Any] = Depends(authenticate_request)):
    """
    Get comprehensive text analysis metrics for monitoring and observability
    Requirements: 8.1, 10.1, 10.3
    """
    return {
        "text_analysis_metrics": text_analysis_metrics.get_comprehensive_metrics(),
        "service_info": {
            "service_name": "Text Analysis API",
            "version": "4.0.0",
            "supported_analysis_types": list(TEXT_MODEL_CONFIG.keys()),
            "supported_entity_types": ["person", "corporate"],
            "total_models": len(TEXT_MODEL_CONFIG)
        },
        "monitoring_capabilities": [
            "Request volume tracking",
            "Latency monitoring", 
            "Success/failure rate analysis",
            "Model response time tracking",
            "Model availability monitoring",
            "Fallback usage tracking",
            "Analysis type performance breakdown",
            "Entity type distribution analysis"
        ]
    }

@app.get("/api/monitoring/dashboard")
async def get_monitoring_dashboard(auth_info: Dict[str, Any] = Depends(authenticate_request)):
    """
    Comprehensive monitoring dashboard combining all metrics and health information
    Requirements: 10.3, 10.4, 10.5
    """
    try:
        # Get all metrics and health information
        text_analysis_metrics_data = text_analysis_metrics.get_comprehensive_metrics()
        security_metrics_data = security_metrics.get_metrics()
        rate_limiting_data = rate_limiter.get_stats()
        text_models_health = await check_text_models_health()
        
        # Calculate overall service health score
        health_score = _calculate_service_health_score(
            text_analysis_metrics_data, 
            text_models_health
        )
        
        # Identify any anomalies or alerts
        alerts = _generate_monitoring_alerts(
            text_analysis_metrics_data,
            text_models_health,
            security_metrics_data
        )
        
        return {
            "dashboard_info": {
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "service_name": "Document Processing & Text Analysis API",
                "version": "4.0.0",
                "overall_health_score": health_score,
                "alert_count": len(alerts)
            },
            "service_health": {
                "overall_status": "healthy" if health_score >= 90 else "degraded" if health_score >= 70 else "unhealthy",
                "health_score": health_score,
                "text_models": text_models_health,
                "infrastructure": {
                    "gcs_status": "healthy",  # Would be checked in real implementation
                    "firestore_status": "healthy",
                    "pubsub_status": "healthy"
                }
            },
            "performance_metrics": {
                "text_analysis": text_analysis_metrics_data,
                "security": security_metrics_data,
                "rate_limiting": rate_limiting_data
            },
            "alerts_and_anomalies": alerts,
            "recommendations": _generate_performance_recommendations(
                text_analysis_metrics_data,
                text_models_health
            ),
            "monitoring_capabilities": {
                "real_time_metrics": True,
                "historical_data": True,
                "alerting": True,
                "performance_analysis": True,
                "security_monitoring": True,
                "model_health_tracking": True,
                "fallback_monitoring": True
            }
        }
        
    except Exception as e:
        return {
            "error": f"Failed to generate monitoring dashboard: {str(e)}",
            "dashboard_info": {
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "service_name": "Document Processing & Text Analysis API",
                "version": "4.0.0",
                "status": "error"
            }
        }

def _calculate_service_health_score(text_metrics: Dict, models_health: Dict) -> float:
    """Calculate overall service health score (0-100)"""
    score = 100.0
    
    # Text analysis success rate (40% weight)
    success_rate = text_metrics["overview"]["success_rate"]
    if success_rate < 95:
        score -= (95 - success_rate) * 0.4
    
    # Model availability (30% weight)
    model_availability = (models_health["healthy_models"] / max(models_health["total_models"], 1)) * 100
    if model_availability < 100:
        score -= (100 - model_availability) * 0.3
    
    # Average latency (20% weight)
    avg_latency = text_metrics["overview"]["avg_latency_ms"]
    if avg_latency > 2000:  # More than 2 seconds
        score -= min((avg_latency - 2000) / 100, 20) * 0.2
    
    # Request volume health (10% weight)
    requests_per_minute = text_metrics["overview"]["requests_per_minute"]
    if requests_per_minute > 50:  # High load
        score -= min((requests_per_minute - 50) / 10, 10) * 0.1
    
    return max(0, round(score, 1))

def _generate_monitoring_alerts(text_metrics: Dict, models_health: Dict, security_metrics: Dict) -> List[Dict]:
    """Generate alerts based on metrics thresholds"""
    alerts = []
    
    # Text analysis performance alerts
    success_rate = text_metrics["overview"]["success_rate"]
    if success_rate < 90:
        alerts.append({
            "type": "performance",
            "severity": "high" if success_rate < 80 else "medium",
            "message": f"Text analysis success rate ({success_rate}%) below threshold",
            "threshold": 90,
            "current_value": success_rate,
            "recommendation": "Check model availability and error logs"
        })
    
    # Model availability alerts
    model_availability = (models_health["healthy_models"] / max(models_health["total_models"], 1)) * 100
    if model_availability < 100:
        alerts.append({
            "type": "availability",
            "severity": "high" if model_availability < 80 else "medium",
            "message": f"Text analysis models availability ({model_availability:.1f}%) degraded",
            "threshold": 100,
            "current_value": model_availability,
            "recommendation": "Check model endpoints and network connectivity"
        })
    
    # Latency alerts
    avg_latency = text_metrics["overview"]["avg_latency_ms"]
    if avg_latency > 5000:
        alerts.append({
            "type": "latency",
            "severity": "high" if avg_latency > 10000 else "medium",
            "message": f"Average text analysis latency ({avg_latency}ms) above threshold",
            "threshold": 5000,
            "current_value": avg_latency,
            "recommendation": "Investigate model response times and system load"
        })
    
    # Security alerts
    security_success_rate = security_metrics.get("success_rate", 1.0)
    if security_success_rate < 0.95:
        alerts.append({
            "type": "security",
            "severity": "high",
            "message": f"Security validation success rate ({security_success_rate:.1%}) below threshold",
            "threshold": 0.95,
            "current_value": security_success_rate,
            "recommendation": "Review security validation logs for suspicious activity"
        })
    
    return alerts

def _generate_performance_recommendations(text_metrics: Dict, models_health: Dict) -> List[str]:
    """Generate performance improvement recommendations"""
    recommendations = []
    
    # Based on success rate
    success_rate = text_metrics["overview"]["success_rate"]
    if success_rate < 95:
        recommendations.append("Consider implementing additional fallback models for better reliability")
    
    # Based on latency
    avg_latency = text_metrics["overview"]["avg_latency_ms"]
    if avg_latency > 3000:
        recommendations.append("Optimize model response times or implement caching for frequently analyzed names")
    
    # Based on model availability
    model_availability = (models_health["healthy_models"] / max(models_health["total_models"], 1)) * 100
    if model_availability < 100:
        recommendations.append("Set up monitoring alerts for model endpoint health checks")
    
    # Based on request volume
    requests_per_minute = text_metrics["overview"]["requests_per_minute"]
    if requests_per_minute > 30:
        recommendations.append("Consider implementing request queuing or rate limiting for high-volume periods")
    
    # Based on failure patterns
    failure_reasons = text_metrics["failure_analysis"]["failure_reasons"]
    if failure_reasons:
        top_failure = max(failure_reasons.items(), key=lambda x: x[1])
        recommendations.append(f"Address top failure reason: {top_failure[0]} ({top_failure[1]} occurrences)")
    
    if not recommendations:
        recommendations.append("System performance is within acceptable parameters")
    
    return recommendations

@app.post("/api/analyze-text/{analysis_type}")
async def submit_text_analysis(
    analysis_type: AnalysisType,
    request: TextAnalysisRequest,
    auth_info: Dict[str, Any] = Depends(authenticate_request)
):
    """
    Submit text-based analysis for person or corporate names
    Supports PEP analysis, negative news, and law involvement screening
    Returns job_id for async status tracking
    Enhanced with comprehensive security validation, authentication, audit logging, and metrics tracking
    """
    start_time = time.time()
    
    # Get model configuration for metrics
    model_config = TEXT_MODEL_CONFIG.get(analysis_type.value, {})
    model_name = model_config.get("model", "unknown")
    
    # Record request start for metrics
    metrics_start_time = text_analysis_metrics.record_request_start(
        analysis_type.value, 
        request.entity_type.value, 
        model_name
    )
    
    print(f"üì§ Received text analysis request: {analysis_type} for {request.entity_type} - '{request.name[:50]}...' from client {auth_info['client_id']}")
    
    try:
        # Additional comprehensive validation using security module
        validation_result = InputSanitizer.validate_analysis_parameters(
            analysis_type.value, 
            request.entity_type.value, 
            request.name
        )
        
        if not validation_result["valid"]:
            # Log security violations
            for violation in validation_result["violations"]:
                security_metrics.record_validation(False, SecurityViolationType.INVALID_CHARACTERS)
            
            # Record metrics failure
            text_analysis_metrics.record_request_failure(
                metrics_start_time, 
                analysis_type.value, 
                request.entity_type.value, 
                model_name, 
                "input_validation_failed"
            )
            
            raise HTTPException(
                status_code=400,
                detail={
                    "error": "Input validation failed",
                    "violations": validation_result["violations"],
                    "suggestions": [
                        "Ensure name contains only letters, numbers, spaces, and basic punctuation",
                        "Check that name length is appropriate",
                        "Remove any special characters or HTML tags"
                    ]
                }
            )
        
        # Log any warnings
        for warning in validation_result["warnings"]:
            print(f"‚ö†Ô∏è Validation warning: {warning}")
        
        # Use sanitized name for processing
        sanitized_name = validation_result["sanitized_name"]
        
        # Validate request parameters and check model availability
        fallback_analysis_type = await validate_text_analysis_request(analysis_type, request.entity_type, sanitized_name)
        
        # Use fallback if primary model is unavailable
        actual_analysis_type = fallback_analysis_type if fallback_analysis_type else analysis_type.value
        actual_model_config = TEXT_MODEL_CONFIG[actual_analysis_type]
        actual_model_name = actual_model_config["model"]
        
        # Record fallback usage if applicable
        if fallback_analysis_type:
            text_analysis_metrics.record_fallback_usage(analysis_type.value, fallback_analysis_type)
        
        # Generate job ID
        job_id = str(uuid.uuid4())
        
        # Log audit trail for sensitive name processing
        log_text_analysis_audit(
            auth_info=auth_info,
            analysis_type=actual_analysis_type,
            entity_type=request.entity_type.value,
            name=sanitized_name,
            job_id=job_id
        )
        
        # Create job record in Firestore with sanitized data
        job_data = create_text_analysis_job_record(
            job_id=job_id,
            analysis_type=actual_analysis_type,
            entity_type=request.entity_type.value,
            name=sanitized_name,  # Use sanitized name
            additional_context=request.additional_context
        )
        
        # Publish message to Pub/Sub for worker processing with sanitized data
        message_id = publish_text_analysis_message(
            job_id=job_id,
            analysis_type=actual_analysis_type,
            entity_type=request.entity_type.value,
            name=sanitized_name,  # Use sanitized name
            additional_context=request.additional_context
        )
        
        processing_time = time.time() - start_time
        
        # Record successful request in metrics
        text_analysis_metrics.record_request_success(
            metrics_start_time,
            actual_analysis_type,
            request.entity_type.value,
            actual_model_name
        )
        
        print(f"‚úÖ Text analysis job submitted: {job_id} in {processing_time:.2f}s")
        
        return {
            "success": True,
            "job_id": job_id,
            "status": JobStatus.SUBMITTED.value,
            "analysis_type": actual_analysis_type,
            "entity_type": request.entity_type.value,
            "name": sanitized_name,  # Return sanitized name
            "model_name": actual_model_name,
            "message_id": message_id,
            "submitted_at": datetime.now(timezone.utc).isoformat(),
            "processing_time": round(processing_time, 2),
            "message": f"Text analysis job submitted successfully. Use GET /api/status/{job_id} to check progress.",
            "fallback_used": fallback_analysis_type is not None,
            "original_analysis_type": analysis_type.value if fallback_analysis_type else None,
            "security_validation": {
                "passed": True,
                "warnings": validation_result["warnings"]
            },
            "rate_limit": {
                "remaining": auth_info["rate_limit"]["remaining"],
                "burst_remaining": auth_info["rate_limit"]["burst_remaining"]
            }
        }
        
    except HTTPException:
        # Record metrics failure for HTTP exceptions (validation errors, auth errors, rate limit errors)
        text_analysis_metrics.record_request_failure(
            metrics_start_time,
            analysis_type.value,
            request.entity_type.value,
            model_name,
            "http_exception"
        )
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"Text analysis job submission failed: {str(e)}"
        print(f"‚ùå {error_msg}")
        
        # Record metrics failure
        text_analysis_metrics.record_request_failure(
            metrics_start_time,
            analysis_type.value,
            request.entity_type.value,
            model_name,
            "internal_error"
        )
        
        # Log security-related failures
        security_metrics.record_validation(False, SecurityViolationType.SUSPICIOUS_PATTERN)
        
        raise HTTPException(
            status_code=500,
            detail={
                "error": error_msg,
                "job_id": job_id if 'job_id' in locals() else None,
                "processing_time": round(processing_time, 2)
            }
        )

# Backward compatibility - default endpoint
@app.post("/api/analyze")
async def analyze_document_default(files: List[UploadFile] = File(...)):
    """Default analyze endpoint (uses SHMSHM model for backward compatibility)"""
    return await submit_analysis(DocumentType.SHMSHM, files)

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)

